# -*- coding: utf-8 -*-
"""s16840_ZUM_NLP_Projekt(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vo0ygeQl9Zw2FY3_CV8KmZhbj3eXg5SX

**Projekt: Analiza Sentymentu**

Autor: Przemysław Brzozowski s16840

Projekt bazuje na danych z twittera z tagu: #Eurovision2023. Dane zostały pobrane 14 Maja
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Etap 1A

##Instalacja
"""

#Poniższe ustawienie encoding na utf-8 naprawia błąd przy instalacji plot_keras_history
import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

!pip install -U spacy -q
!pip install transformers==4.28.0
!python -m spacy download en_core_web_lg -q
!pip install plot_keras_history -q
!pip install -U datasets -q

import transformers
from transformers import pipeline

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import spacy
import re
from re import sub
from wordcloud import WordCloud

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

from sklearn.svm import LinearSVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc

import logging
import numpy as np

import tensorflow as tf
import keras
from keras.models import Sequential
from keras import layers
from keras.preprocessing.text import Tokenizer
from keras import regularizers
from keras.callbacks import ModelCheckpoint
from keras.utils import pad_sequences, to_categorical

logging.basicConfig(format="%(levelname)s - %(asctime)s: %(message)s", datefmt= '%H:%M:%S', level=logging.INFO)

"""##Ładowanie danych"""

folder_path='/content/drive/MyDrive/'
file_path=f'{folder_path}Tweets_Eurovision2023.csv'
df=pd.read_csv(file_path).dropna().drop_duplicates()
df.sample(5)

df.shape

df.info()

"""##Klasyfikacja Zero-shot: Facebook bart-large-mnli"""

#Define pipeline
classifier = pipeline(task="zero-shot-classification",
                      model="facebook/bart-large-mnli",
                      device=0)

"""###Klasyfikacja (zajmuje ok 40 minut)"""

sequences = df['tweetText'].to_list()
candidate_labels = ["positive","neutral","negative"]
hypothesis_template="The sentiment of this text is {}"
hf_prediction = classifier(sequences,candidate_labels,hypothesis_template=hypothesis_template)

hf_prediction = pd.DataFrame(hf_prediction)
hf_prediction.head()

hf_prediction['hf_prediction'] = hf_prediction['labels'].apply(lambda x: x[0])
hf_prediction['hf_prediction'] = hf_prediction['hf_prediction'].map({'positive':1,'neutral':0,'negative':-1})
hf_prediction['hf_predicted_score']= hf_prediction['scores'].apply(lambda x: x[0])
hf_prediction = hf_prediction.drop(['labels','scores'],axis=1)

hf_prediction = pd.DataFrame(hf_prediction)
hf_prediction.sample(5)

hf_prediction.groupby(['hf_prediction']).count()

predicted_df=df
predicted_df['predicted']=hf_prediction["hf_prediction"]

predicted_df.head()

predicted_df.to_csv('hf_predictions.csv',index=False)

"""###Ładowanie z pliku (dla przyspieszenia prezentacji)"""

file_path=f'{folder_path}hf_predictions.csv'
predicted_df=pd.read_csv(file_path)
predicted_df.sample(5)

predicted_df.predicted.value_counts(ascending=True).plot.barh()
plt.title('Class distribution')
plt.show()

plot_df=predicted_df
plot_df['words per tweet']=predicted_df['tweetText'].str.split().apply(len)
plot_df.boxplot('words per tweet', by='predicted',grid=False,showfliers=False)
plt.suptitle("")
plt.xlabel("")
plt.show()

"""###Czyszczenie danych"""

nlp=spacy.load("en_core_web_lg",disable=['ner','parser'])
nlp.add_pipe('sentencizer')

def clean_text(text):
    text = str(text)
    text = text.lower()

    # Clean the text
    text = sub(r'((www.[^\s]+)|(https?://[^\s]+))','',text)
    text = sub(r"'", " ", text)
    text = sub(r"^@?(\w){1,15}$", " ", text)
    text = sub(r"#[A-Za-z0-9_]+"," ",text)
    text = sub(r"[^A-Za-z0-9^,!?.\/'+]", " ", text)
    text = re.sub('[()!?]', ' ', text)
    text = re.sub('\[.*?\]',' ', text)
    text = re.sub("[^a-z0-9]"," ", text)

    return text

predicted_df.tweetText = predicted_df.tweetText.apply(lambda x: clean_text(x))

file_model = predicted_df.copy()
file_model = file_model[file_model.tweetText.str.len()>1]
file_model.sample(5)

def remove_stopwords(text):
  return ' '.join(filter(lambda x: x not in nlp.Defaults.stop_words,text.split()))

def lemmatize(text):
  return ' '.join([x.lemma_ for x in nlp(text)])

predicted_df.tweetText = predicted_df.tweetText.apply(remove_stopwords)
predicted_df.tweetText = predicted_df.tweetText.apply(lemmatize)
predicted_df.sample(5)

"""###Word Cloud"""

text = ' '.join(predicted_df.tweetText)
wc=WordCloud(max_words=1000,width = 1600,height = 800,collocations=False).generate(text)
wc.to_image()

"""#Etap 2: Classic ML"""

X_train, X_test, y_train, y_test = train_test_split(predicted_df.tweetText, predicted_df.predicted, test_size=0.25,stratify=predicted_df.predicted,random_state=42)

y_train.value_counts()

y_test.value_counts()

vectorizer = TfidfVectorizer(ngram_range=(1,2),max_features=500000)
vectorizer.fit(X_train)

len(vectorizer.get_feature_names_out())

X_train=vectorizer.transform(X_train)
X_test=vectorizer.transform(X_test)

def plot_conf_matrix(y_test,y_pred):
  cf_matrix=confusion_matrix(y_test,y_pred)
  #plot_confusion_matrix(cf_matrix,classes=["Positive","Neutral","Negative"])
  plt.figure(figsize=(5,4))
  sns.heatmap(cf_matrix, annot=True)
  plt.title('Confusion Matrix')
  plt.ylabel('Actal Values')
  plt.xlabel('Predicted Values')
  plt.show()

def print_roc(y_test,y_pred):
  fpr, tpr = roc_curve(y_test, y_pred, pos_label=1)
  roc_auc = auc(fpr, tpr)
  plt.figure()
  plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)
  plt.xlim([0.0, 1.0])
  plt.ylim([0.0, 1.05])
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('ROC CURVE')
  plt.legend(loc="lower right")
  plt.show()

def model_test(model,X_train,X_test,y_train,y_test):
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  print(classification_report(y_test,y_pred))
  print("Accuracy: ",accuracy_score(y_test,y_pred))
  plot_conf_matrix(y_test,y_pred)
  print_roc(y_test,y_pred)

"""##Bernoulli Naive Bayes Model"""

model_test(BernoulliNB(),X_train,X_test,y_train,y_test)

"""##SVC Model"""

model_test(LinearSVC(),X_train,X_test,y_train,y_test)

"""##Logistic Regression Model"""

model_test(LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1),X_train,X_test,y_train,y_test)

"""#Etap 3: Neural Model

##Ładowanie danych
"""

max_words=10000
max_len=200

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(predicted_df.tweetText)
tweet_sequences=tokenizer.texts_to_sequences(predicted_df.tweetText)
padded_tweets = pad_sequences(tweet_sequences,maxlen=max_len)
print(padded_tweets)

tweet_labels=to_categorical(predicted_df.predicted,num_classes=3)

X_train2,X_test2,y_train2,y_test2 = train_test_split(padded_tweets,tweet_labels,test_size=0.2,stratify=tweet_labels,random_state=42)

padded_tweets.shape

tweet_labels.shape

from plot_keras_history import show_history, plot_history

def showPlot_history(history):
  show_history(history)
  plot_history(history)
  plt.close()

"""##Testowanie różnych modeli.
Testuję 3 różne modele z różnymi parametrami w celu poprawienia parametru dokładności. Wszystkie modele, mimo zastosowania różnych parametrów, uzyskały średni wynik Accuracy ok. 77%

###Model 1:
"""

def my_model1(model_name,max_words,output_dim,input_len,lstm_units,lstm_dropout,dense_units,optimizer,epochs):
  my_model = Sequential()
  my_model.add(layers.Embedding(max_words, output_dim, input_length=input_len))
  my_model.add(layers.Bidirectional(layers.LSTM(lstm_units,dropout=lstm_dropout)))
  my_model.add(layers.Dense(dense_units,activation='softmax'))

  my_model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])

  checkpoint = ModelCheckpoint(model_name, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)
  history = my_model.fit(X_train2, y_train2, epochs=epochs,validation_data=(X_test2, y_test2),callbacks=[checkpoint])
  #show plot
  showPlot_history(history)

  # Print out the accuracy of the model on the test set
  model_scores = my_model.evaluate(X_test2, y_test2, verbose=0)
  print("Model loss on the test dataset: {0:.2f}%".format(model_scores[0]*100))
  print("Model accuracy on the test dataset: {0:.2f}%".format(model_scores[1]*100))

my_model1(f"{folder_path}best_model1.hdf5",max_words,40,max_len,20,0.6,3,keras.optimizers.RMSprop(learning_rate=0.0001),60)

my_model1(f"{folder_path}best_model2.hdf5",max_words,128,max_len,200,0.7,3,keras.optimizers.RMSprop(learning_rate=0.0001),50)

"""###Model 2:"""

def my_model2(model_name,max_words,output_dim,lstm_units,lstm_dropout,dense_units,optimizer,epochs):
  my_model2 = Sequential()
  my_model2.add(layers.Embedding(max_words, output_dim))
  my_model2.add(layers.LSTM(lstm_units,dropout=lstm_dropout))
  my_model2.add(layers.Dense(dense_units,activation='softmax'))

  my_model2.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])

  checkpoint2 = ModelCheckpoint(model_name, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)
  history2 = my_model2.fit(X_train2, y_train2, epochs=epochs,validation_data=(X_test2, y_test2),callbacks=[checkpoint2],batch_size=64)
  #show plot
  showPlot_history(history2)

  # Print out the accuracy of the model on the test set
  model_scores = my_model2.evaluate(X_test2, y_test2, verbose=0)
  print("Model loss on the test dataset: {0:.2f}%".format(model_scores[0]*100))
  print("Model accuracy on the test dataset: {0:.2f}%".format(model_scores[1]*100))

my_model2(f"{folder_path}best_model3.hdf5",max_words,20,128,0.7,3,keras.optimizers.RMSprop(learning_rate=0.0001),50)

my_model2(f"{folder_path}best_model4.hdf5",max_words,40,192,0.7,3,keras.optimizers.RMSprop(learning_rate=0.0001),50)

"""###Model 3 (dodatkowo)"""

#Próba uruchomienia modelu z parametrem recurrent_dropout ustawionym na 0.2. Trenowanie 10 epok zajęło ok 37 minut z powodu przekroczenia kryteriów cuDNN (recurrent_dropout>0) przez co moc GPU nie była wykorzystana. Brak widocznej poprawy
my_model3 = Sequential()
my_model3.add(layers.Embedding(max_words, 128))
my_model3.add(layers.LSTM(128,dropout=0.2,recurrent_dropout=0.2))
my_model3.add(layers.Dense(3,activation='softmax'))

my_model3.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint3 = ModelCheckpoint("test_best_model.hdf5", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)
history3 = my_model3.fit(X_train2, y_train2,batch_size=32, epochs=10,validation_data=(X_test2, y_test2),callbacks=[checkpoint3])

show_history(history3)
plot_history(history3)
plt.close()

"""#Etap 4: Language Model

##Ładowanie danych do obiektu dataset
"""

from datasets import Dataset

new_df = predicted_df.rename(columns={'tweetText':'text','predicted':'label'})
new_df['label'] = new_df['label'].replace({-1:0,0:1,1:2}) #Default labels result in erros. Replacing labels to be >0
print(new_df.head())

dataset_ = Dataset.from_pandas(new_df)
dataset = dataset_.train_test_split(0.1)

print(dataset)

print(dataset['test'][0])

"""##Konfiguracja modelu"""

model_checkpoint='distilbert-base-uncased'
batch_size=128

from transformers import AutoTokenizer

tokenizer=AutoTokenizer.from_pretrained(model_checkpoint,use_fast=True)

tokenizer("Hello")

dataset['train']

def process(x):
  return tokenizer(x['text'],padding=True,truncation=True)

dataset_encoded=dataset.map(process,batched=True,batch_size=None)

dataset_encoded['train'].column_names

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer

model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels=3).to("cuda")

args = TrainingArguments(
    model_checkpoint,
    evaluation_strategy='epoch',
    save_strategy='epoch',
    learning_rate=float('2e-5'),
    per_device_train_batch_size=batch_size,
    num_train_epochs=5,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model='accuracy'
    )

import numpy as np
import datasets
metric=datasets.load_metric('glue','sst2')

def compute_metrics(eval_preds):
  logits,labels = eval_preds
  predictions=np.argmax(logits,axis=-1)
  return metric.compute(predictions=predictions,references=labels)

trainer = Trainer(model=model,
                  args=args,
                  train_dataset=dataset_encoded['train'],
                  eval_dataset=dataset_encoded['test'],
                  tokenizer=tokenizer,
                  compute_metrics=compute_metrics)

dataset_encoded['train'].info

dataset_encoded['train'][1]

trainer.evaluate(eval_dataset=[dataset_encoded['train'][1]])

"""Trenowanie modelu"""

trainer.train()

trainer.evaluate()

trainer.model

trainer.save_model(f"{folder_path}my_distilbert_model/")

preds_output=trainer.predict(dataset_encoded['test'])

preds_output.metrics

"""##Testowanie modelu"""

my_distilbert_model=AutoModelForSequenceClassification.from_pretrained(f"{folder_path}my_distilbert_model/").to("cuda")

import torch

def myBERTclassifier(text):
  classes=['negative','neutral','positive']
  tokens=tokenizer(text)
  tokenlist=[tokens['input_ids']]
  token_torch=torch.tensor(tokenlist).to("cuda")
  output=my_distilbert_model(token_torch)
  
  res=output.logits.argmax().item()
  return classes[res]

myBERTclassifier("I am feeling good!")

myBERTclassifier("I hate you!!")

for i in range(0,5):
  text=dataset_encoded['test']['text'][i]
  print(text)
  print(myBERTclassifier(text))

test_list=predicted_df['tweetText'].head(5).to_list()
for el in test_list:
  print(el)
  print(myBERTclassifier(el))